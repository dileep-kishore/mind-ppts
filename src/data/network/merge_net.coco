#!/usr/bin/env coconut-run

import json
from toolz import unique, count, merge

def load_data(fpath: str) -> dict:
    with open(fpath, 'r') as fid:
        datum = json.load(fid)
    return datum

def get_uniq_nodes(data: dict[]) -> dict[]:
    return (data
            |> map$(.['nodes'])
            |> reduce$(::)
            |> unique$(?, key=(x) -> x['id'])
            |> list)

def get_link_key(link: dict) -> set:
    return frozenset([link['source'], link['target']])

def get_overlap_links(data: dict[]) -> dict[]:
    all_links = (data
                |> fmap$(.['links'])
                |> reduce$(+))
    return (all_links
            |> filter$((e1) -> (all_links
                                |> filter$((e2) -> get_link_key(e1) == get_link_key(e2))
                                |> count
                                |> (e3) -> True if e3 > 1 else False))
            |> unique$(?, key=get_link_key)
            |> list)

def get_single_links(data: dict[], overlaps: dict[]) -> dict[]:
    all_links = (data
                |> fmap$(.['links'])
                |> reduce$(+))
    common_keys = overlaps |> fmap$(get_link_key)
    return (all_links
            |> filter$((e1) -> get_link_key(e1) not in common_keys)
            |> list)

class MyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        else:
            return super(MyEncoder, self).default(obj)

def main(sources: str[]) -> None:
    data = sources |> fmap$(load_data)
    uniq_nodes = get_uniq_nodes(data)
    overlap_links = (get_overlap_links(data)
                        |> fmap$((ol) -> {**ol, **{'type': 'overlap'}}))
    single_links = (get_single_links(data, overlap_links)
                        |> fmap$((sl) -> {**sl, **{'type': 'single'}}))
    print(single_links[0])
    merged_net = merge({'nodes': uniq_nodes}, {'links': overlap_links + single_links})
    with open('stool_saliva_network.json', 'w') as fid:
        json.dump(merged_net, fid, indent=2, sort_keys=True, cls=MyEncoder)

if __name__ == '__main__':
    source1 = 'saliva_network.json'
    source2 = 'stool_network.json'
    main([source1, source2])